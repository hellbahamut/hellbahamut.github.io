import{_ as i,c as a,o as n,a2 as t}from"./chunks/framework.C2eRlmqf.js";const c=JSON.parse('{"title":"模块六：无监督学习","description":"K-Means聚类与PCA降维","frontmatter":{"title":"模块六：无监督学习","description":"K-Means聚类与PCA降维","order":6},"headers":[],"relativePath":"guide/03-ml-basics/06-unsupervised.md","filePath":"guide/03-ml-basics/06-unsupervised.md","lastUpdated":1768553241000}'),e={name:"guide/03-ml-basics/06-unsupervised.md"};function l(h,s,p,r,k,d){return n(),a("div",null,[...s[0]||(s[0]=[t(`<h1 id="模块六-无监督学习" tabindex="-1">模块六：无监督学习 <a class="header-anchor" href="#模块六-无监督学习" aria-label="Permalink to &quot;模块六：无监督学习&quot;">​</a></h1><h2 id="_6-1-聚类-clustering" tabindex="-1">6.1 聚类 (Clustering) <a class="header-anchor" href="#_6-1-聚类-clustering" aria-label="Permalink to &quot;6.1 聚类 (Clustering)&quot;">​</a></h2><h3 id="_6-1-1-k-means-⭐⭐⭐⭐⭐" tabindex="-1">6.1.1 K-Means ⭐⭐⭐⭐⭐ <a class="header-anchor" href="#_6-1-1-k-means-⭐⭐⭐⭐⭐" aria-label="Permalink to &quot;6.1.1 K-Means ⭐⭐⭐⭐⭐&quot;">​</a></h3><ul><li><strong>算法</strong>: <ol><li>随机初始化K个中心。</li><li>将每个点分配给最近的中心。</li><li>更新中心为簇内均值。</li><li>重复直到收敛。</li></ol></li><li><strong>K的选择</strong>: 肘部法则 (Elbow Method)。</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sklearn.cluster </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KMeans</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kmeans </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KMeans(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">n_clusters</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kmeans.fit(X)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">labels </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> kmeans.labels_</span></span></code></pre></div><h3 id="_6-1-2-dbscan" tabindex="-1">6.1.2 DBSCAN <a class="header-anchor" href="#_6-1-2-dbscan" aria-label="Permalink to &quot;6.1.2 DBSCAN&quot;">​</a></h3><p>基于密度的聚类，不需要指定K，能发现任意形状的簇，且能识别噪声。</p><h2 id="_6-2-降维-dimensionality-reduction" tabindex="-1">6.2 降维 (Dimensionality Reduction) <a class="header-anchor" href="#_6-2-降维-dimensionality-reduction" aria-label="Permalink to &quot;6.2 降维 (Dimensionality Reduction)&quot;">​</a></h2><h3 id="_6-2-1-pca-主成分分析-⭐⭐⭐⭐⭐" tabindex="-1">6.2.1 PCA (主成分分析) ⭐⭐⭐⭐⭐ <a class="header-anchor" href="#_6-2-1-pca-主成分分析-⭐⭐⭐⭐⭐" aria-label="Permalink to &quot;6.2.1 PCA (主成分分析) ⭐⭐⭐⭐⭐&quot;">​</a></h3><ul><li><strong>原理</strong>: 将数据投影到方差最大的方向（主成分），去除相关性，保留主要信息。</li><li><strong>应用</strong>: 可视化、去噪、加速训练。</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sklearn.decomposition </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> PCA</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">pca </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PCA(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">n_components</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.95</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 保留95%的方差</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X_pca </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pca.fit_transform(X)</span></span></code></pre></div><h3 id="_6-2-2-t-sne" tabindex="-1">6.2.2 t-SNE <a class="header-anchor" href="#_6-2-2-t-sne" aria-label="Permalink to &quot;6.2.2 t-SNE&quot;">​</a></h3><p>用于高维数据的可视化（降维到2D或3D），能很好地保留局部结构。</p>`,13)])])}const E=i(e,[["render",l]]);export{c as __pageData,E as default};
